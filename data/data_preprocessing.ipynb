{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA and intermediate results will be saved in: ./data_preprocessing_pipeline_outputs/20250518_231709\n",
      "\n",
      "--- 1. Processing Weather Data ---\n",
      "  Processing weather file: ./weather/4기상청_속초_풍속(2017~2023).csv\n",
      "\n",
      "--- Exploring weather_processed_4기상청_속초_풍속(2017~2023).csv_0 (Shape: (2557, 5)) ---\n",
      "Head:\n",
      "         Date Station_ID Station_Name  AvgWindSpd(m/s)  MaxWindSpd(m/s)\n",
      "0   2017.1.1         90           속초              1.7              5.8\n",
      "1  2017.1.10         90           속초              2.4              6.6\n",
      "2  2017.1.11         90           속초              2.4              7.5\n",
      "3  2017.1.12         90           속초              4.1              8.6\n",
      "4  2017.1.13         90           속초              3.2              6.4\n",
      "\n",
      "Missing Values:\n",
      " AvgWindSpd(m/s)    5\n",
      "MaxWindSpd(m/s)    5\n",
      "Date               0\n",
      "Station_ID         0\n",
      "Station_Name       0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        AvgWindSpd(m/s)  MaxWindSpd(m/s)\n",
      "count      2552.000000      2552.000000\n",
      "mean          1.908111         4.768064\n",
      "std           0.723179         1.640203\n",
      "min           0.400000         1.600000\n",
      "25%           1.400000         3.500000\n",
      "50%           1.800000         4.600000\n",
      "75%           2.300000         5.700000\n",
      "max           6.000000        13.400000\n",
      "Numeric distributions plot saved for weather_processed_4기상청_속초_풍속(2017~2023).csv_0.\n",
      "  Processing weather file: ./weather/1기상청_속초_기온(2017~2023).csv\n",
      "\n",
      "--- Exploring weather_processed_1기상청_속초_기온(2017~2023).csv_1 (Shape: (2557, 9)) ---\n",
      "Head:\n",
      "         Date Station_ID Station_Name  AvgTempC(℃)  MaxTempC(℃) TimeOfMaxTempC  \\\n",
      "0   2017.1.1         90           속초          6.0          9.8          12:24   \n",
      "1  2017.1.10         90           속초          0.4          6.2           0:03   \n",
      "2  2017.1.11         90           속초         -1.2          2.8          13:52   \n",
      "3  2017.1.12         90           속초          0.8          4.6          13:21   \n",
      "4  2017.1.13         90           속초         -2.7          1.2          14:09   \n",
      "\n",
      "   MinTempC(℃) TimeOfMinTempC  Diurnal_Temperature_Range  \n",
      "0          1.5           6:39                        8.3  \n",
      "1         -2.9          23:39                        9.1  \n",
      "2         -5.3           4:36                        8.1  \n",
      "3         -2.6       24:00:00                        7.2  \n",
      "4         -5.5           7:51                        6.7  \n",
      "\n",
      "Missing Values:\n",
      " AvgTempC(℃)                  3\n",
      "MaxTempC(℃)                  1\n",
      "MinTempC(℃)                  1\n",
      "Diurnal_Temperature_Range    1\n",
      "Date                         0\n",
      "Station_ID                   0\n",
      "Station_Name                 0\n",
      "TimeOfMaxTempC               0\n",
      "TimeOfMinTempC               0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        AvgTempC(℃)  MaxTempC(℃)  MinTempC(℃)  Diurnal_Temperature_Range\n",
      "count  2554.000000  2556.000000  2556.000000                2556.000000\n",
      "mean     13.263547    17.490923     9.179851                   8.311072\n",
      "std       9.224951     9.293251     9.604468                   2.933141\n",
      "min     -13.000000    -9.000000   -16.200000                   1.000000\n",
      "25%       5.700000     9.800000     1.200000                   6.400000\n",
      "50%      14.100000    18.700000     9.400000                   8.300000\n",
      "75%      21.200000    25.000000    17.400000                  10.100000\n",
      "max      32.000000    38.700000    29.100000                  22.300000\n",
      "Numeric distributions plot saved for weather_processed_1기상청_속초_기온(2017~2023).csv_1.\n",
      "  Processing weather file: ./weather/3기상청_속초_습도(2017~2023).csv\n",
      "\n",
      "--- Exploring weather_processed_3기상청_속초_습도(2017~2023).csv_2 (Shape: (2557, 4)) ---\n",
      "Head:\n",
      "         Date Station_ID Station_Name  Avg_Humidity_pct(%rh)\n",
      "0   2017.1.1         90           속초                   50.0\n",
      "1  2017.1.10         90           속초                   27.4\n",
      "2  2017.1.11         90           속초                   24.1\n",
      "3  2017.1.12         90           속초                   28.9\n",
      "4  2017.1.13         90           속초                   30.0\n",
      "\n",
      "Missing Values:\n",
      " Avg_Humidity_pct(%rh)    3\n",
      "Date                     0\n",
      "Station_ID               0\n",
      "Station_Name             0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        Avg_Humidity_pct(%rh)\n",
      "count            2554.000000\n",
      "mean               62.190603\n",
      "std                21.636396\n",
      "min                13.100000\n",
      "25%                43.600000\n",
      "50%                64.100000\n",
      "75%                81.500000\n",
      "max                98.500000\n",
      "Numeric distributions plot saved for weather_processed_3기상청_속초_습도(2017~2023).csv_2.\n",
      "  Processing weather file: ./weather/2기상청_속초_강수량(2017~2023).csv\n",
      "\n",
      "--- Exploring weather_processed_2기상청_속초_강수량(2017~2023).csv_3 (Shape: (2557, 4)) ---\n",
      "Head:\n",
      "         Date Station_ID Station_Name  Precipitation_mm(mm)\n",
      "0   2017.1.1         90           속초                   NaN\n",
      "1  2017.1.10         90           속초                   NaN\n",
      "2  2017.1.11         90           속초                   NaN\n",
      "3  2017.1.12         90           속초                   NaN\n",
      "4  2017.1.13         90           속초                   NaN\n",
      "\n",
      "Missing Values:\n",
      " Precipitation_mm(mm)    1594\n",
      "Date                       0\n",
      "Station_ID                 0\n",
      "Station_Name               0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        Precipitation_mm(mm)\n",
      "count            963.000000\n",
      "mean              11.456179\n",
      "std               26.496119\n",
      "min                0.000000\n",
      "25%                0.000000\n",
      "50%                1.900000\n",
      "75%               11.400000\n",
      "max              368.700000\n",
      "Numeric distributions plot saved for weather_processed_2기상청_속초_강수량(2017~2023).csv_3.\n",
      "Weather data processed and merged. Shape: (1734, 13)\n",
      "\n",
      "--- 2. Processing Accident Data ---\n",
      "\n",
      "--- Exploring accident_summary_속초시 (Shape: (405, 4)) ---\n",
      "Head:\n",
      "         Date  Total_Rescued_Count Accident_Cause_List Accident_Outcome_List\n",
      "0 2018-01-02                    1              [일반조난]                [인명구조]\n",
      "1 2018-02-03                    2              [일반조난]                [인명구조]\n",
      "2 2018-02-10                    2              [일반조난]                [인명구조]\n",
      "3 2018-02-14                    1              [일반조난]                [인명구조]\n",
      "4 2018-03-31                    1              [실족추락]                [인명구조]\n",
      "\n",
      "Missing Values:\n",
      " Date                     0\n",
      "Total_Rescued_Count      0\n",
      "Accident_Cause_List      0\n",
      "Accident_Outcome_List    0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        Total_Rescued_Count\n",
      "count           405.000000\n",
      "mean              1.814815\n",
      "std               1.481830\n",
      "min               0.000000\n",
      "25%               1.000000\n",
      "50%               1.000000\n",
      "75%               2.000000\n",
      "max               9.000000\n",
      "Numeric distributions plot saved for accident_summary_속초시.\n",
      "속초시 accident data summarized. Shape: (405, 4)\n",
      "\n",
      "--- 3. Processing Visitor Data ---\n",
      "\n",
      "--- Exploring visitor_설악동_daily (Shape: (1734, 2)) ---\n",
      "Head:\n",
      "         Date  Total_Visitor_Count\n",
      "0 2018-01-01                 7454\n",
      "1 2018-01-02                 4462\n",
      "2 2018-01-03                 4826\n",
      "3 2018-01-04                 3245\n",
      "4 2018-01-05                 3805\n",
      "\n",
      "Missing Values:\n",
      " Date                   0\n",
      "Total_Visitor_Count    0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        Total_Visitor_Count\n",
      "count          1734.000000\n",
      "mean           4460.555363\n",
      "std            3488.004358\n",
      "min               0.000000\n",
      "25%            2319.500000\n",
      "50%            3534.500000\n",
      "75%            5543.750000\n",
      "max           30193.000000\n",
      "Numeric distributions plot saved for visitor_설악동_daily.\n",
      "설악동 visitor data processed. Shape: (1734, 2)\n",
      "\n",
      "--- 4. Merging All Processed Data ---\n",
      "  Merged AccidentSummary data. Current shape: (1734, 4)\n",
      "  Merged WeatherFinal data. Current shape: (1734, 16)\n",
      "  Merged SeorakdongVisitor data. Current shape: (1734, 17)\n",
      "\n",
      "--- 5. Applying Final Touches and EDA on Merged Data ---\n",
      "\n",
      "--- Exploring final_merged_data_before_save (Shape: (1734, 17)) ---\n",
      "Head:\n",
      "         Date  Total_Rescued_Count Accident_Cause_List Accident_Outcome_List  \\\n",
      "0 2018-01-01                  0.0                  []                    []   \n",
      "1 2018-01-02                  1.0              [일반조난]                [인명구조]   \n",
      "2 2018-01-03                  0.0                  []                    []   \n",
      "3 2018-01-04                  0.0                  []                    []   \n",
      "4 2018-01-05                  0.0                  []                    []   \n",
      "\n",
      "  Station_ID Station_Name  AvgWindSpd(m/s)  MaxWindSpd(m/s)  AvgTempC(℃)  \\\n",
      "0         90           속초              2.6              6.4          1.0   \n",
      "1         90           속초              2.9              7.0          1.5   \n",
      "2         90           속초              1.6              3.7         -1.6   \n",
      "3         90           속초              1.5              3.3         -1.0   \n",
      "4         90           속초              1.2              2.8          1.5   \n",
      "\n",
      "   MaxTempC(℃) TimeOfMaxTempC  MinTempC(℃) TimeOfMinTempC  \\\n",
      "0          4.2          14:43         -3.2           3:43   \n",
      "1          5.6          13:58         -2.1          23:44   \n",
      "2          3.3          14:32         -5.5           7:32   \n",
      "3          2.2          14:49         -5.7           3:42   \n",
      "4          7.2          13:31         -1.4           8:06   \n",
      "\n",
      "   Diurnal_Temperature_Range  Avg_Humidity_pct(%rh)  Precipitation_mm(mm)  \\\n",
      "0                        7.4                   21.3                   0.0   \n",
      "1                        7.7                   21.8                   0.0   \n",
      "2                        8.8                   29.9                   0.0   \n",
      "3                        7.9                   53.3                   0.0   \n",
      "4                        8.6                   45.4                   0.0   \n",
      "\n",
      "   Total_Visitor_Count  \n",
      "0                 7454  \n",
      "1                 4462  \n",
      "2                 4826  \n",
      "3                 3245  \n",
      "4                 3805  \n",
      "\n",
      "Missing Values:\n",
      " Date                         0\n",
      "MaxTempC(℃)                  0\n",
      "Precipitation_mm(mm)         0\n",
      "Avg_Humidity_pct(%rh)        0\n",
      "Diurnal_Temperature_Range    0\n",
      "TimeOfMinTempC               0\n",
      "MinTempC(℃)                  0\n",
      "TimeOfMaxTempC               0\n",
      "AvgTempC(℃)                  0\n",
      "Total_Rescued_Count          0\n",
      "MaxWindSpd(m/s)              0\n",
      "AvgWindSpd(m/s)              0\n",
      "Station_Name                 0\n",
      "Station_ID                   0\n",
      "Accident_Outcome_List        0\n",
      "Accident_Cause_List          0\n",
      "Total_Visitor_Count          0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive Statistics (Numeric):\n",
      "        Total_Rescued_Count  AvgWindSpd(m/s)  MaxWindSpd(m/s)  AvgTempC(℃)  \\\n",
      "count          1734.000000      1734.000000      1734.000000  1734.000000   \n",
      "mean              0.423875         1.927624         4.765571    13.463725   \n",
      "std               1.049675         0.719182         1.603004     9.231979   \n",
      "min               0.000000         0.500000         0.000000   -13.000000   \n",
      "25%               0.000000         1.400000         3.600000     5.900000   \n",
      "50%               0.000000         1.800000         4.600000    14.450000   \n",
      "75%               0.000000         2.300000         5.700000    21.300000   \n",
      "max               9.000000         5.800000        13.400000    32.000000   \n",
      "\n",
      "       MaxTempC(℃)  MinTempC(℃)  Diurnal_Temperature_Range  \\\n",
      "count  1734.000000  1734.000000                 1734.00000   \n",
      "mean     17.673645     9.423645                    8.25000   \n",
      "std       9.294504     9.616426                    2.96364   \n",
      "min      -9.000000   -16.200000                    1.10000   \n",
      "25%      10.100000     1.500000                    6.30000   \n",
      "50%      18.900000     9.650000                    8.20000   \n",
      "75%      25.200000    17.800000                   10.10000   \n",
      "max      38.700000    29.100000                   22.30000   \n",
      "\n",
      "       Avg_Humidity_pct(%rh)  Precipitation_mm(mm)  Total_Visitor_Count  \n",
      "count            1734.000000           1734.000000          1734.000000  \n",
      "mean               62.502941              4.405479          4460.555363  \n",
      "std                21.660781             17.294058          3488.004358  \n",
      "min                13.100000              0.000000             0.000000  \n",
      "25%                44.150000              0.000000          2319.500000  \n",
      "50%                65.300000              0.000000          3534.500000  \n",
      "75%                81.825000              0.300000          5543.750000  \n",
      "max                98.400000            226.200000         30193.000000  \n",
      "Numeric distributions plot saved for final_merged_data_before_save.\n",
      "Final merged data correlation heatmap saved.\n",
      "\n",
      "--- Final Merged Data Saved to preprocessed_merged_data.csv ---\n",
      "Final DataFrame shape: (1734, 17)\n",
      "Final columns: ['Date', 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List', 'Station_ID', 'Station_Name', 'AvgWindSpd(m/s)', 'MaxWindSpd(m/s)', 'AvgTempC(℃)', 'MaxTempC(℃)', 'TimeOfMaxTempC', 'MinTempC(℃)', 'TimeOfMinTempC', 'Diurnal_Temperature_Range', 'Avg_Humidity_pct(%rh)', 'Precipitation_mm(mm)', 'Total_Visitor_Count']\n",
      "Sample of final data:\n",
      "          Date  Total_Rescued_Count Accident_Cause_List Accident_Outcome_List  \\\n",
      "0  2018-01-01                  0.0                  []                    []   \n",
      "1  2018-01-02                  1.0              [일반조난]                [인명구조]   \n",
      "2  2018-01-03                  0.0                  []                    []   \n",
      "3  2018-01-04                  0.0                  []                    []   \n",
      "4  2018-01-05                  0.0                  []                    []   \n",
      "\n",
      "  Station_ID Station_Name  AvgWindSpd(m/s)  MaxWindSpd(m/s)  AvgTempC(℃)  \\\n",
      "0         90           속초              2.6              6.4          1.0   \n",
      "1         90           속초              2.9              7.0          1.5   \n",
      "2         90           속초              1.6              3.7         -1.6   \n",
      "3         90           속초              1.5              3.3         -1.0   \n",
      "4         90           속초              1.2              2.8          1.5   \n",
      "\n",
      "   MaxTempC(℃) TimeOfMaxTempC  MinTempC(℃) TimeOfMinTempC  \\\n",
      "0          4.2          14:43         -3.2           3:43   \n",
      "1          5.6          13:58         -2.1          23:44   \n",
      "2          3.3          14:32         -5.5           7:32   \n",
      "3          2.2          14:49         -5.7           3:42   \n",
      "4          7.2          13:31         -1.4           8:06   \n",
      "\n",
      "   Diurnal_Temperature_Range  Avg_Humidity_pct(%rh)  Precipitation_mm(mm)  \\\n",
      "0                        7.4                   21.3                   0.0   \n",
      "1                        7.7                   21.8                   0.0   \n",
      "2                        8.8                   29.9                   0.0   \n",
      "3                        7.9                   53.3                   0.0   \n",
      "4                        8.6                   45.4                   0.0   \n",
      "\n",
      "   Total_Visitor_Count  \n",
      "0                 7454  \n",
      "1                 4462  \n",
      "2                 4826  \n",
      "3                 3245  \n",
      "4                 3805  \n",
      "\n",
      "========== All Data Processing and Merging Complete ==========\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import platform\n",
    "\n",
    "# --- 0. Configuration ---\n",
    "# Input File Paths\n",
    "ACCIDENT_RAW_FILE = \"./accident/전국 산악사고 구조활동현황(2017~2021).csv\"\n",
    "WEATHER_DATA_DIR = './weather/'\n",
    "VISITOR_RAW_FILE = \"./accident/국립공원공단_국립공원 시간별 일별 탐방객 통계_20221024.csv\"\n",
    "\n",
    "# Output File\n",
    "FINAL_OUTPUT_MERGED_FILE = \"preprocessed_merged_data.csv\" # 최종 출력 파일명\n",
    "\n",
    "# Common Settings\n",
    "COMMON_DATE_COLUMN = 'Date' # 최종적으로 사용할 날짜 컬럼명 (영문)\n",
    "START_DATE_STR = \"2018-01-01\"\n",
    "END_DATE_STR = \"2022-09-30\"\n",
    "\n",
    "# Specific Settings\n",
    "TARGET_DISTRICT_FOR_VISITORS = \"설악동\"\n",
    "TARGET_WEATHER_STATION_NAME = '속초'\n",
    "ACCIDENT_CITY_FILTER = '속초시'\n",
    "\n",
    "# --- Directory Setup for EDA ---\n",
    "CURRENT_TIME_STR_EDA = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "BASE_RESULTS_DIR_EDA = \"./data_preprocessing_pipeline_outputs\"\n",
    "RUN_SPECIFIC_DIR_EDA = os.path.join(BASE_RESULTS_DIR_EDA, CURRENT_TIME_STR_EDA)\n",
    "os.makedirs(RUN_SPECIFIC_DIR_EDA, exist_ok=True)\n",
    "print(f\"EDA and intermediate results will be saved in: {RUN_SPECIFIC_DIR_EDA}\")\n",
    "\n",
    "# --- Matplotlib Font Setup ---\n",
    "if platform.system() == 'Windows': plt.rc('font', family='Malgun Gothic')\n",
    "elif platform.system() == 'Darwin': plt.rc('font', family='AppleGothic')\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# --- Column Mapping Dictionaries ---\n",
    "# Weather: Standard Korean -> Final English\n",
    "weather_col_map_std_korean_to_english = {\n",
    "    '일시': COMMON_DATE_COLUMN, '최대풍속(m/s)': 'MaxWindSpd(m/s)', '평균풍속(m/s)': 'AvgWindSpd(m/s)',\n",
    "    '최고기온(℃)': 'MaxTempC(℃)', '최저기온(℃)': 'MinTempC(℃)', '평균기온(℃)': 'AvgTempC(℃)',\n",
    "    '최고기온시각': 'TimeOfMaxTempC', '최저기온시각': 'TimeOfMinTempC', '일교차': 'Diurnal_Temperature_Range',\n",
    "    '평균습도(%rh)': 'Avg_Humidity_pct(%rh)', '강수량(mm)': 'Precipitation_mm(mm)',\n",
    "    '지점번호': 'Station_ID', '지점명': 'Station_Name'\n",
    "}\n",
    "# Accident: Original Korean -> Final English\n",
    "accident_col_map_korean_to_english = {\n",
    "    '신고년월일': COMMON_DATE_COLUMN, '발생장소_구': 'Accident_City_District',\n",
    "    '구조인원': 'Total_Rescued_Count', '사고원인코드명_사고종별': 'Accident_Cause_Raw',\n",
    "    '처리결과코드': 'Outcome_Code_Raw'\n",
    "}\n",
    "# Visitor: Original Korean -> Final English\n",
    "visitor_col_map_korean_to_english = {\n",
    "    '일자': COMMON_DATE_COLUMN, '관리지구': 'District_Name',\n",
    "    '전체 탐방객수': 'Total_Visitor_Count' # 최종적으로 사용할 탐방객 수 컬럼명\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def try_read_csv_with_encodings(file_path):\n",
    "    for enc in ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=enc)\n",
    "            for col in df.select_dtypes(include='object').columns:\n",
    "                df[col] = df[col].astype(str).str.strip().str.replace('\\t', '', regex=False)\n",
    "            return df\n",
    "        except UnicodeDecodeError: continue\n",
    "        except Exception as e: print(f\"Error reading {file_path} with {enc}: {e}\"); continue\n",
    "    print(f\"Warning: Could not read or decode {file_path}. Skipping this file.\")\n",
    "    return None\n",
    "\n",
    "def normalize_and_rename_cols(df, col_map_to_english):\n",
    "    df.columns = [col.strip().replace('\\t', '') for col in df.columns]\n",
    "\n",
    "    if col_map_to_english: # 2. Rename to English\n",
    "        rename_map = {k: v for k, v in col_map_to_english.items() if k in df.columns}\n",
    "        if rename_map: df.rename(columns=rename_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_date_column(df, current_date_col, final_date_col):\n",
    "    if current_date_col not in df.columns:\n",
    "        print(f\"Warning: Date column '{current_date_col}' not found. Skipping date processing.\"); return df\n",
    "    df[current_date_col] = df[current_date_col].astype(str).str.replace('.', '-', regex=False).str.strip()\n",
    "    df[final_date_col] = pd.to_datetime(df[current_date_col], errors='coerce')\n",
    "    if current_date_col != final_date_col:\n",
    "        df.drop(columns=[current_date_col], inplace=True, errors='ignore')\n",
    "    df.dropna(subset=[final_date_col], inplace=True)\n",
    "    return df\n",
    "\n",
    "def explore_dataframe(df, df_name, save_dir):\n",
    "    if df is None or df.empty: print(f\"\\n--- Exploring {df_name} ---\\nDataFrame is empty. Skipping.\"); return\n",
    "    print(f\"\\n--- Exploring {df_name} (Shape: {df.shape}) ---\")\n",
    "    print(\"Head:\\n\", df.head())\n",
    "    print(\"\\nMissing Values:\\n\", df.isnull().sum().sort_values(ascending=False)) # 결측치 많은 순으로 정렬\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    if not numeric_df.empty: print(\"\\nDescriptive Statistics (Numeric):\\n\", numeric_df.describe())\n",
    "    \n",
    "    if not numeric_df.empty:\n",
    "        numeric_sample = numeric_df.sample(min(1000, len(numeric_df))) # 샘플링 유지\n",
    "        num_cols = len(numeric_sample.columns)\n",
    "        if num_cols > 0:\n",
    "            n_plots_per_row = 5 # 한 줄에 표시할 그래프 수\n",
    "            n_rows = (num_cols + n_plots_per_row - 1) // n_plots_per_row\n",
    "            \n",
    "            # 전체 그림(figure) 크기를 컬럼 수에 따라 좀 더 유동적으로 조절\n",
    "            fig_width = 15 \n",
    "            fig_height = max(5, n_rows * 3.5) # 행당 높이 조절\n",
    "            \n",
    "            fig, axes = plt.subplots(n_rows, n_plots_per_row, figsize=(fig_width, fig_height))\n",
    "            axes = axes.flatten() # 다차원 배열을 1차원으로 만들어 순회 용이하게 함\n",
    "\n",
    "            for i, col in enumerate(numeric_sample.columns):\n",
    "                if i < len(axes): # 생성된 subplot 개수만큼만 그림\n",
    "                    sns.histplot(numeric_sample[col].dropna(), kde=True, bins=30, ax=axes[i])\n",
    "                    # --- 제목 글씨 크기 조절 ---\n",
    "                    axes[i].set_title(f'Distribution of {col}', fontsize=10) # 예: 폰트 크기를 10으로 설정\n",
    "                    axes[i].set_xlabel(col, fontsize=9) # x축 레이블 크기도 조절 (선택적)\n",
    "                    axes[i].set_ylabel('Count', fontsize=9) # y축 레이블 크기도 조절 (선택적)\n",
    "                else:\n",
    "                    break # 더 이상 그릴 subplot이 없으면 중단\n",
    "            \n",
    "            # 남는 빈 subplot 숨기기\n",
    "            for j in range(i + 1, len(axes)):\n",
    "                fig.delaxes(axes[j])\n",
    "\n",
    "            plt.tight_layout(pad=2.0) # subplot 간 간격 및 전체 레이아웃 조정, pad 값으로 여백 조절\n",
    "            plt.savefig(os.path.join(save_dir, f\"{df_name}_numeric_distributions.png\")); plt.close(fig) # fig 명시적 닫기\n",
    "            print(f\"Numeric distributions plot saved for {df_name}.\")\n",
    "\n",
    "# --- Data Processing Functions ---\n",
    "def process_weather_data(weather_dir, k_to_e_map, date_col_final, station_name, eda_save_dir):\n",
    "    print(\"\\n--- 1. Processing Weather Data ---\")\n",
    "    csv_files = glob.glob(os.path.join(weather_dir, '*.csv'))\n",
    "    csv_files = [f for f in csv_files if not (f.endswith('combined_weather_data.csv') or FINAL_OUTPUT_MERGED_FILE in f)]\n",
    "    if not csv_files: print(\"No weather CSV files found.\"); return pd.DataFrame(columns=[date_col_final])\n",
    "\n",
    "    df_weather_merged = pd.DataFrame(pd.date_range(start=START_DATE_STR, end=END_DATE_STR, freq='D'), columns=[date_col_final])\n",
    "\n",
    "    for idx, file in enumerate(csv_files):\n",
    "        print(f\"  Processing weather file: {file}\")\n",
    "        df_w_raw = try_read_csv_with_encodings(file)\n",
    "        if df_w_raw is None: continue\n",
    "        \n",
    "        df_w_english = normalize_and_rename_cols(df_w_raw, col_map_to_english=k_to_e_map) # 영문명으로 변경\n",
    "\n",
    "        if not df_w_english.empty and date_col_final in df_w_english.columns:\n",
    "            df_w_english = df_w_english.groupby(date_col_final, as_index=False).first()\n",
    "            explore_dataframe(df_w_english, f\"weather_processed_{os.path.basename(file)}_{idx}\", eda_save_dir)\n",
    "            \n",
    "            cols_to_merge = [col for col in df_w_english.columns if col == date_col_final or col not in df_weather_merged.columns]\n",
    "            if len(cols_to_merge) > 1:\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df_weather_merged[date_col_final]):\n",
    "                    df_weather_merged[date_col_final] = pd.to_datetime(df_weather_merged[date_col_final], errors='coerce')\n",
    "                    df_weather_merged.dropna(subset=[date_col_final], inplace=True)\n",
    "                    \n",
    "                # df_w_english의 Date 컬럼도 확실히 datetime64[ns]로 만듦\n",
    "                if not pd.api.types.is_datetime64_any_dtype(df_w_english[date_col_final]):\n",
    "                    df_w_english[date_col_final] = pd.to_datetime(df_w_english[date_col_final], errors='coerce')\n",
    "                    df_w_english.dropna(subset=[date_col_final], inplace=True)\n",
    "                df_weather_merged = pd.merge(df_weather_merged, df_w_english[cols_to_merge], on=date_col_final, how='left')\n",
    "    \n",
    "    if df_weather_merged.empty or len(df_weather_merged.columns) <= 1:\n",
    "        print(\"Warning: No valid weather data could be merged.\"); return pd.DataFrame(columns=[date_col_final])\n",
    "    print(f\"Weather data processed and merged. Shape: {df_weather_merged.shape}\")\n",
    "    return df_weather_merged\n",
    "\n",
    "def process_accident_data(file_path, k_to_e_map, date_col_final, city_filter, start_str, end_str, eda_save_dir):\n",
    "    print(\"\\n--- 2. Processing Accident Data ---\")\n",
    "    df_raw = try_read_csv_with_encodings(file_path)\n",
    "    if df_raw is None: return pd.DataFrame(columns=[date_col_final])\n",
    "    \n",
    "    df_processed = normalize_and_rename_cols(df_raw, col_map_to_english=k_to_e_map)\n",
    "    df_processed = process_date_column(df_processed, date_col_final, date_col_final) # 이미 영문명 'Date'\n",
    "\n",
    "    city_col_actual = 'Accident_City_District' # 영문명 사용\n",
    "    if city_col_actual in df_processed.columns and city_filter:\n",
    "        df_filtered_city = df_processed[df_processed[city_col_actual] == city_filter].copy()\n",
    "    else: df_filtered_city = df_processed.copy()\n",
    "\n",
    "    if not df_filtered_city.empty and date_col_final in df_filtered_city.columns:\n",
    "        start_dt, end_dt = pd.to_datetime(start_str), pd.to_datetime(end_str)\n",
    "        df_filtered_date = df_filtered_city[(df_filtered_city[date_col_final] >= start_dt) & (df_filtered_city[date_col_final] <= end_dt)]\n",
    "        if df_filtered_date.empty: print(f\"No accident data for '{city_filter}' in date range.\"); return pd.DataFrame(columns=[date_col_final, 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List'])\n",
    "\n",
    "        def list_agg(s): return [str(i) for i in s if pd.notna(i) and str(i).strip() != '']\n",
    "        agg_rules = {'Total_Rescued_Count': ('Total_Rescued_Count', 'sum')}\n",
    "        if 'Accident_Cause_Raw' in df_filtered_date.columns: agg_rules['Accident_Cause_List'] = ('Accident_Cause_Raw', list_agg)\n",
    "        if 'Outcome_Code_Raw' in df_filtered_date.columns: agg_rules['Accident_Outcome_List'] = ('Outcome_Code_Raw', list_agg)\n",
    "        df_summary = df_filtered_date.groupby(date_col_final, as_index=False).agg(**agg_rules)\n",
    "        explore_dataframe(df_summary, f\"accident_summary_{city_filter.lower()}\", eda_save_dir)\n",
    "        print(f\"{city_filter} accident data summarized. Shape: {df_summary.shape}\")\n",
    "        return df_summary\n",
    "    print(f\"No accident data for '{city_filter}' to summarize.\"); return pd.DataFrame(columns=[date_col_final, 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List'])\n",
    "\n",
    "def process_visitor_data(file_path, k_to_e_map, date_col_final, district_filter, start_str, end_str, eda_save_dir):\n",
    "    print(\"\\n--- 3. Processing Visitor Data ---\")\n",
    "    df_raw = try_read_csv_with_encodings(file_path)\n",
    "    if df_raw is None: return pd.DataFrame(columns=[date_col_final])\n",
    "\n",
    "    df_processed = normalize_and_rename_cols(df_raw, col_map_to_english=k_to_e_map)\n",
    "    df_processed = process_date_column(df_processed, date_col_final, date_col_final)\n",
    "    \n",
    "    start_dt, end_dt = pd.to_datetime(start_str), pd.to_datetime(end_str)\n",
    "    df_filtered_date = df_processed[(df_processed[date_col_final] >= start_dt) & (df_processed[date_col_final] <= end_dt)]\n",
    "    if df_filtered_date.empty: print(\"No visitor data in date range.\"); return pd.DataFrame(columns=[date_col_final, 'Total_Visitor_Count'])\n",
    "\n",
    "    df_district_daily = pd.DataFrame(columns=[date_col_final, 'Total_Visitor_Count']) # 최종 컬럼명 사용\n",
    "    if 'District_Name' in df_filtered_date.columns and district_filter:\n",
    "        df_district_raw = df_filtered_date[df_filtered_date['District_Name'] == district_filter].copy()\n",
    "        if not df_district_raw.empty:\n",
    "            # 'Total_Visitor_Count' 컬럼이 visitor_col_map_korean_to_english에 의해 이미 생성됨\n",
    "            df_district_daily = df_district_raw.groupby(date_col_final, as_index=False)['Total_Visitor_Count'].sum()\n",
    "    explore_dataframe(df_district_daily, f\"visitor_{district_filter.lower()}_daily\", eda_save_dir)\n",
    "    print(f\"{district_filter} visitor data processed. Shape: {df_district_daily.shape}\")\n",
    "    return df_district_daily\n",
    "\n",
    "# --- Main Data Processing Pipeline ---\n",
    "if __name__ == '__main__':\n",
    "    df_weather = process_weather_data(WEATHER_DATA_DIR, weather_col_map_std_korean_to_english, COMMON_DATE_COLUMN, \n",
    "                                      TARGET_WEATHER_STATION_NAME, RUN_SPECIFIC_DIR_EDA)\n",
    "    \n",
    "    df_accident = process_accident_data(ACCIDENT_RAW_FILE, accident_col_map_korean_to_english, \n",
    "                                        COMMON_DATE_COLUMN, ACCIDENT_CITY_FILTER, START_DATE_STR, END_DATE_STR, RUN_SPECIFIC_DIR_EDA)\n",
    "    \n",
    "    df_seorakdong_visitor = process_visitor_data(\n",
    "        VISITOR_RAW_FILE, visitor_col_map_korean_to_english, COMMON_DATE_COLUMN, \n",
    "        TARGET_DISTRICT_FOR_VISITORS, START_DATE_STR, END_DATE_STR, RUN_SPECIFIC_DIR_EDA\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- 4. Merging All Processed Data ---\")\n",
    "    try:\n",
    "        start_dt_m = pd.to_datetime(START_DATE_STR); end_dt_m = pd.to_datetime(END_DATE_STR)\n",
    "        final_df = pd.DataFrame(pd.date_range(start=start_dt_m, end=end_dt_m, freq='D'), columns=[COMMON_DATE_COLUMN])\n",
    "    except Exception as e: print(f\"Error creating date range for final merge: {e}\"); exit()\n",
    "\n",
    "    dataframes_to_merge = [df_accident, df_weather, df_seorakdong_visitor] \n",
    "    df_names_for_log = [\"AccidentSummary\", \"WeatherFinal\", \"SeorakdongVisitor\"]\n",
    "    \n",
    "    for i, df_component in enumerate(dataframes_to_merge):\n",
    "        df_name = df_names_for_log[i]\n",
    "        if df_component is not None and not df_component.empty and COMMON_DATE_COLUMN in df_component.columns:\n",
    "            if not pd.api.types.is_datetime64_any_dtype(df_component[COMMON_DATE_COLUMN]):\n",
    "                df_component[COMMON_DATE_COLUMN] = pd.to_datetime(df_component[COMMON_DATE_COLUMN], errors='coerce')\n",
    "            final_df = pd.merge(final_df, df_component, on=COMMON_DATE_COLUMN, how='left')\n",
    "            print(f\"  Merged {df_name} data. Current shape: {final_df.shape}\")\n",
    "        else:\n",
    "            print(f\"  Skipping merge for {df_name} data (None, empty, or no date column).\")\n",
    "\n",
    "    print(\"\\n--- 5. Applying Final Touches and EDA on Merged Data ---\")\n",
    "    for col in final_df.columns:\n",
    "        if col == COMMON_DATE_COLUMN: continue\n",
    "        # 결측치 처리 전에 실제 타입 확인\n",
    "        # 첫 번째 유효한 값의 타입을 기준으로 리스트인지, 숫자인지, 그 외인지 판단\n",
    "        first_valid_idx = final_df[col].first_valid_index()\n",
    "        if first_valid_idx is not None:\n",
    "            first_valid_type = type(final_df[col].loc[first_valid_idx])\n",
    "            if pd.api.types.is_numeric_dtype(final_df[col].dtype) or np.issubdtype(first_valid_type, np.number):\n",
    "                final_df[col].fillna(0, inplace=True)\n",
    "            elif first_valid_type == list:\n",
    "                final_df[col] = final_df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "            else: # Default to empty string for other types or all NaN columns\n",
    "                final_df[col].fillna(\"\", inplace=True)\n",
    "        else: # 컬럼 전체가 NaN인 경우\n",
    "            if pd.api.types.is_numeric_dtype(final_df[col].dtype): final_df[col].fillna(0, inplace=True)\n",
    "            else: final_df[col].fillna(\"\", inplace=True) # 또는 [] 등 기본값 설정\n",
    "    \n",
    "    explore_dataframe(final_df, \"final_merged_data_before_save\", RUN_SPECIFIC_DIR_EDA)\n",
    "\n",
    "    numeric_cols_final = final_df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if len(numeric_cols_final) > 1:\n",
    "        plt.figure(figsize=(max(15, len(numeric_cols_final)), max(12, len(numeric_cols_final)-2))) # 크기 조정\n",
    "        sns.heatmap(final_df[numeric_cols_final].corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 8}) # annot 글자 크기\n",
    "        plt.title('Correlation Matrix of Final Merged Data', fontsize=15)\n",
    "        plt.xticks(fontsize=10); plt.yticks(fontsize=10) # 눈금 글자 크기\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(RUN_SPECIFIC_DIR_EDA, \"final_merged_data_correlation_heatmap.png\")); plt.close()\n",
    "        print(\"Final merged data correlation heatmap saved.\")\n",
    "\n",
    "    final_df[COMMON_DATE_COLUMN] = final_df[COMMON_DATE_COLUMN].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    final_df.to_csv(FINAL_OUTPUT_MERGED_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n--- Final Merged Data Saved to {FINAL_OUTPUT_MERGED_FILE} ---\")\n",
    "    print(f\"Final DataFrame shape: {final_df.shape}\")\n",
    "    print(\"Final columns:\", final_df.columns.tolist())\n",
    "    print(\"Sample of final data:\\n\", final_df.head())\n",
    "\n",
    "    print(\"\\n========== All Data Processing and Merging Complete ==========\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
