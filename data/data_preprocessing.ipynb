{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Processing Weather Data ---\n",
      "  Processing weather file: ./weather/4기상청_속초_풍속(2017~2023).csv\n",
      "  Processing weather file: ./weather/1기상청_속초_기온(2017~2023).csv\n",
      "  Processing weather file: ./weather/3기상청_속초_습도(2017~2023).csv\n",
      "  Processing weather file: ./weather/2기상청_속초_강수량(2017~2023).csv\n",
      "Weather data processed and merged. Shape: (1734, 11)\n",
      "\n",
      "--- 2. Processing Accident Data ---\n",
      "Sokcho accident data summarized. Shape: (405, 4)\n",
      "\n",
      "--- 3. Processing Visitor Data ---\n",
      "Seorakdong visitor data processed. Shape: (1734, 2)\n",
      "\n",
      "--- 4. Merging All Processed Data ---\n",
      "  Merged dataframe component 1. Current shape: (1734, 4)\n",
      "  Merged dataframe component 2. Current shape: (1734, 14)\n",
      "  Merged dataframe component 3. Current shape: (1734, 15)\n",
      "\n",
      "--- 5. Applying Final Touches ---\n",
      "\n",
      "--- Final Merged Data Saved to final_merged_seorak_data_refactored.csv ---\n",
      "Final DataFrame shape: (1734, 15)\n",
      "Final columns: ['Date', 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List', 'AvgWindSpd(m/s)', 'MaxWindSpd(m/s)', 'AvgTempC(℃)', 'MaxTempC(℃)', 'TimeOfMaxTempC', 'MinTempC(℃)', 'TimeOfMinTempC', 'Diurnal_Temperature_Range', 'Avg_Humidity_pct(%rh)', 'Precipitation_mm(mm)', 'Total_Visitor_Count']\n",
      "Sample of final data:\n",
      "         Date  Total_Rescued_Count Accident_Cause_List Accident_Outcome_List  \\\n",
      "0  2018-01-01                  0.0                                             \n",
      "1  2018-01-02                  1.0              [일반조난]                [인명구조]   \n",
      "2  2018-01-03                  0.0                                             \n",
      "3  2018-01-04                  0.0                                             \n",
      "4  2018-01-05                  0.0                                             \n",
      "\n",
      "   AvgWindSpd(m/s)  MaxWindSpd(m/s)  AvgTempC(℃)  MaxTempC(℃) TimeOfMaxTempC  \\\n",
      "0              2.6              6.4          1.0          4.2          14:43   \n",
      "1              2.9              7.0          1.5          5.6          13:58   \n",
      "2              1.6              3.7         -1.6          3.3          14:32   \n",
      "3              1.5              3.3         -1.0          2.2          14:49   \n",
      "4              1.2              2.8          1.5          7.2          13:31   \n",
      "\n",
      "   MinTempC(℃) TimeOfMinTempC  Diurnal_Temperature_Range  \\\n",
      "0         -3.2           3:43                        7.4   \n",
      "1         -2.1          23:44                        7.7   \n",
      "2         -5.5           7:32                        8.8   \n",
      "3         -5.7           3:42                        7.9   \n",
      "4         -1.4           8:06                        8.6   \n",
      "\n",
      "   Avg_Humidity_pct(%rh)  Precipitation_mm(mm)  Total_Visitor_Count  \n",
      "0                   21.3                   0.0                 7454  \n",
      "1                   21.8                   0.0                 4462  \n",
      "2                   29.9                   0.0                 4826  \n",
      "3                   53.3                   0.0                 3245  \n",
      "4                   45.4                   0.0                 3805  \n",
      "\n",
      "========== All Data Processing and Merging Complete ==========\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import ast # 문자열 리스트 변환용\n",
    "from datetime import datetime\n",
    "\n",
    "# --- 0. Configuration ---\n",
    "ACCIDENT_RAW_FILE = \"./accident/전국 산악사고 구조활동현황(2017~2021).csv\"\n",
    "WEATHER_DATA_DIR = './weather/'\n",
    "VISITOR_RAW_FILE = \"./accident/국립공원공단_국립공원 시간별 일별 탐방객 통계_20221024.csv\"\n",
    "FINAL_OUTPUT_MERGED_FILE = \"preprocessed_data.csv\" # 파일명 변경\n",
    "COMMON_DATE_COLUMN = 'Date'\n",
    "START_DATE_STR = \"2018-01-01\"\n",
    "END_DATE_STR = \"2022-09-30\"\n",
    "TARGET_DISTRICT_FOR_VISITORS = \"설악동\"\n",
    "TARGET_WEATHER_STATION_NAME = '속초' # 날씨 데이터를 필터링할 지점명\n",
    "\n",
    "# Column Mapping Dictionaries (이전과 동일하게 유지 또는 필요시 수정)\n",
    "weather_col_map_to_std_korean = {\n",
    "    '지점번호': ['지점번호'], '지점명': ['지점명'], '일시': ['일시', '날짜'],\n",
    "    '평균풍속(m/s)': ['평균풍속(m/s)', '평균풍속'], '최대풍속(m/s)': ['최대풍속(m/s)', '최대풍속'],\n",
    "    '평균기온(℃)': ['평균기온(℃)', '평균기온'], '최고기온(℃)': ['최고기온(℃)', '최고기온'],\n",
    "    '최저기온(℃)': ['최저기온(℃)', '최저기온'], '최고기온시각': ['최고기온시각'],\n",
    "    '최저기온시각': ['최저기온시각'], '일교차': ['일교차'],\n",
    "    '평균습도(%rh)': ['평균습도(%rh)', '평균습도'], '강수량(mm)': ['강수량(mm)', '강수량']\n",
    "}\n",
    "weather_col_map_korean_to_english = {\n",
    "    '일시': COMMON_DATE_COLUMN, '최대풍속(m/s)': 'MaxWindSpd(m/s)', '평균풍속(m/s)': 'AvgWindSpd(m/s)',\n",
    "    '최고기온(℃)': 'MaxTempC(℃)', '최저기온(℃)': 'MinTempC(℃)', '평균기온(℃)': 'AvgTempC(℃)',\n",
    "    '최고기온시각': 'TimeOfMaxTempC', '최저기온시각': 'TimeOfMinTempC', '일교차': 'Diurnal_Temperature_Range',\n",
    "    '평균습도(%rh)': 'Avg_Humidity_pct(%rh)', '강수량(mm)': 'Precipitation_mm(mm)'\n",
    "}\n",
    "accident_col_map_korean_to_english = {\n",
    "    '신고년월일': COMMON_DATE_COLUMN, '발생장소_구': 'Accident_City_District',\n",
    "    '구조인원': 'Total_Rescued_Count', '사고원인코드명_사고종별': 'Accident_Cause_Raw',\n",
    "    '처리결과코드': 'Outcome_Code_Raw'\n",
    "}\n",
    "visitor_col_map_korean_to_english = {\n",
    "    '일자': COMMON_DATE_COLUMN, '관리지구': 'District_Name',\n",
    "    '전체 탐방객수': 'Total_Visitor_Count_Raw'\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def try_read_csv_with_encodings(file_path):\n",
    "    # ... (이전과 동일) ...\n",
    "    for enc in ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']:\n",
    "        try: return pd.read_csv(file_path, encoding=enc)\n",
    "        except UnicodeDecodeError: continue\n",
    "        except Exception as e: print(f\"Error reading {file_path} with {enc}: {e}\"); continue\n",
    "    print(f\"Warning: Could not read or decode {file_path}. Skipping this file.\")\n",
    "    return None\n",
    "\n",
    "def normalize_and_rename_cols(df, std_korean_map, eng_map=None):\n",
    "    # ... (이전과 동일, inplace=True 사용) ...\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    for target_col, possible_names in std_korean_map.items():\n",
    "        for col_name in possible_names:\n",
    "            if col_name in df.columns and target_col != col_name:\n",
    "                df.rename(columns={col_name: target_col}, inplace=True)\n",
    "                break\n",
    "    if eng_map:\n",
    "        rename_map_eng = {k: v for k, v in eng_map.items() if k in df.columns}\n",
    "        if rename_map_eng: df.rename(columns=rename_map_eng, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_date_col(df, current_date_col_name, target_date_col_name):\n",
    "    # ... (이전과 동일, errors='coerce' 후 dropna 고려) ...\n",
    "    if current_date_col_name not in df.columns:\n",
    "        print(f\"Warning: Date column '{current_date_col_name}' not found. Skipping date processing.\"); return df\n",
    "    df[current_date_col_name] = df[current_date_col_name].astype(str).str.replace('.', '-', regex=False).str.strip()\n",
    "    df[target_date_col_name] = pd.to_datetime(df[current_date_col_name], errors='coerce')\n",
    "    if current_date_col_name != target_date_col_name:\n",
    "        df.drop(columns=[current_date_col_name], inplace=True, errors='ignore')\n",
    "    df.dropna(subset=[target_date_col_name], inplace=True) # 유효하지 않은 날짜 행 제거\n",
    "    return df\n",
    "\n",
    "# --- Data Processing Functions for Each Source ---\n",
    "def process_weather_data(weather_dir, std_korean_map, eng_map, date_col, target_station_name):\n",
    "    print(\"\\n--- 1. Processing Weather Data ---\")\n",
    "    csv_files = glob.glob(os.path.join(weather_dir, '*.csv'))\n",
    "    csv_files = [f for f in csv_files if not (f.endswith('combined_weather_data.csv') or f.endswith(FINAL_OUTPUT_MERGED_FILE))]\n",
    "    \n",
    "    if not csv_files: print(\"No weather CSV files found.\"); return pd.DataFrame(columns=[date_col])\n",
    "\n",
    "    # 기준이 될 전체 날짜 범위 생성 (병합의 기준으로 사용)\n",
    "    try:\n",
    "        start_dt = pd.to_datetime(START_DATE_STR); end_dt = pd.to_datetime(END_DATE_STR)\n",
    "        df_weather_merged = pd.DataFrame(pd.date_range(start=start_dt, end=end_dt, freq='D'), columns=[date_col])\n",
    "    except Exception as e: print(f\"Error creating date range for weather: {e}\"); return pd.DataFrame(columns=[date_col])\n",
    "\n",
    "    for file in csv_files:\n",
    "        print(f\"  Processing weather file: {file}\")\n",
    "        df_w_component_raw = try_read_csv_with_encodings(file)\n",
    "        if df_w_component_raw is None: continue\n",
    "        \n",
    "        df_w_component = normalize_and_rename_cols(df_w_component_raw, std_korean_map) # 1차: 표준 한글\n",
    "        df_w_component = process_date_col(df_w_component, '일시', date_col) # 표준 한글 '일시' -> 최종 'Date'\n",
    "\n",
    "        if '지점명' in df_w_component.columns and target_station_name:\n",
    "            df_w_component = df_w_component[df_w_component['지점명'] == target_station_name].copy()\n",
    "            df_w_component.drop(columns=['지점번호', '지점명'], inplace=True, errors='ignore')\n",
    "        \n",
    "        if not df_w_component.empty and date_col in df_w_component.columns:\n",
    "            df_w_component = df_w_component.groupby(date_col, as_index=False).first() # 날짜별 유일값\n",
    "            # 영문명 변경은 모든 컴포넌트 병합 후 한 번에 하거나, 여기서 각 컴포넌트별로 수행\n",
    "            df_w_component = normalize_and_rename_cols(df_w_component, {}, eng_map) # 2차: 영문명 (eng_map만 사용)\n",
    "            \n",
    "            # COMMON_DATE_COLUMN 외의 컬럼만 가져와서 병합\n",
    "            cols_to_merge = [date_col] + [col for col in df_w_component.columns if col != date_col and col not in df_weather_merged.columns]\n",
    "            if len(cols_to_merge) > 1:\n",
    "                 df_weather_merged = pd.merge(df_weather_merged, df_w_component[cols_to_merge], on=date_col, how='left')\n",
    "    \n",
    "    if df_weather_merged.empty or len(df_weather_merged.columns) <= 1:\n",
    "        print(\"Warning: No valid weather data could be processed and merged.\"); \n",
    "        return pd.DataFrame(columns=[date_col]) # 빈 DataFrame 반환\n",
    "    print(f\"Weather data processed and merged. Shape: {df_weather_merged.shape}\")\n",
    "    return df_weather_merged\n",
    "\n",
    "def process_accident_data(accident_file, eng_map, date_col, start_date, end_date):\n",
    "    print(\"\\n--- 2. Processing Accident Data ---\")\n",
    "    df_raw = try_read_csv_with_encodings(accident_file)\n",
    "    if df_raw is None: return pd.DataFrame(columns=[date_col])\n",
    "    \n",
    "    df_processed = normalize_and_rename_cols(df_raw, {}, eng_map) # 바로 영문명으로\n",
    "    df_processed = process_date_col(df_processed, date_col, date_col) # COMMON_DATE_COLUMN으로 이미 변경됨\n",
    "\n",
    "    city_col = 'Accident_City_District' if 'Accident_City_District' in df_processed.columns else '발생장소_구'\n",
    "    if city_col in df_processed.columns:\n",
    "        df_sokcho = df_processed[df_processed[city_col] == '속초시'].copy()\n",
    "    else: df_sokcho = df_processed.copy()\n",
    "\n",
    "    if not df_sokcho.empty and date_col in df_sokcho.columns:\n",
    "        # 날짜 범위 필터링\n",
    "        df_sokcho = df_sokcho[(df_sokcho[date_col] >= pd.to_datetime(start_date)) & (df_sokcho[date_col] <= pd.to_datetime(end_date))]\n",
    "        if df_sokcho.empty: print(\"No Sokcho accident data in the specified date range.\"); return pd.DataFrame(columns=[date_col, 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List'])\n",
    "\n",
    "        def list_agg(series): return [str(item) for item in series if pd.notna(item) and str(item).strip() != '']\n",
    "        agg_rules = {'Total_Rescued_Count': ('Total_Rescued_Count', 'sum')}\n",
    "        if 'Accident_Cause_Raw' in df_sokcho.columns: agg_rules['Accident_Cause_List'] = ('Accident_Cause_Raw', list_agg)\n",
    "        if 'Outcome_Code_Raw' in df_sokcho.columns: agg_rules['Accident_Outcome_List'] = ('Outcome_Code_Raw', list_agg)\n",
    "        df_summary = df_sokcho.groupby(date_col, as_index=False).agg(**agg_rules)\n",
    "        print(f\"Sokcho accident data summarized. Shape: {df_summary.shape}\")\n",
    "        return df_summary\n",
    "    print(\"No Sokcho accident data to summarize.\"); return pd.DataFrame(columns=[date_col, 'Total_Rescued_Count', 'Accident_Cause_List', 'Accident_Outcome_List'])\n",
    "\n",
    "def process_visitor_data(visitor_file, eng_map, date_col, target_district, start_date, end_date):\n",
    "    print(\"\\n--- 3. Processing Visitor Data ---\")\n",
    "    df_raw = try_read_csv_with_encodings(visitor_file)\n",
    "    if df_raw is None: return pd.DataFrame(columns=[date_col]), pd.DataFrame(columns=[date_col])\n",
    "\n",
    "    df_processed = normalize_and_rename_cols(df_raw, {}, eng_map)\n",
    "    df_processed = process_date_col(df_processed, date_col, date_col)\n",
    "    \n",
    "    # 날짜 범위 필터링\n",
    "    df_filtered_by_date = df_processed[(df_processed[date_col] >= pd.to_datetime(start_date)) & (df_processed[date_col] <= pd.to_datetime(end_date))]\n",
    "    if df_filtered_by_date.empty: print(\"No visitor data in the specified date range.\"); return pd.DataFrame(columns=[date_col]), pd.DataFrame(columns=[date_col])\n",
    "\n",
    "    # 설악동 데이터\n",
    "    df_seorakdong_daily = pd.DataFrame(columns=[date_col, 'Total_Visitor_Count']) # 최종 컬럼명 사용\n",
    "    if 'District_Name' in df_filtered_by_date.columns:\n",
    "        df_seorakdong_raw = df_filtered_by_date[df_filtered_by_date['District_Name'] == target_district].copy()\n",
    "        if not df_seorakdong_raw.empty:\n",
    "            df_seorakdong_daily = df_seorakdong_raw.groupby(date_col, as_index=False)['Total_Visitor_Count_Raw'].sum()\n",
    "            df_seorakdong_daily.rename(columns={'Total_Visitor_Count_Raw': 'Total_Visitor_Count'}, inplace=True) # 최종 컬럼명\n",
    "    print(f\"Seorakdong visitor data processed. Shape: {df_seorakdong_daily.shape}\")\n",
    "    \n",
    "    return df_seorakdong_daily\n",
    "\n",
    "# --- Main Data Processing Pipeline ---\n",
    "if __name__ == '__main__':\n",
    "    df_weather = process_weather_data(WEATHER_DATA_DIR, weather_col_map_to_std_korean, \n",
    "                                      weather_col_map_korean_to_english, COMMON_DATE_COLUMN, \n",
    "                                      TARGET_WEATHER_STATION_NAME)\n",
    "    \n",
    "    df_accident = process_accident_data(ACCIDENT_RAW_FILE, accident_col_map_korean_to_english, \n",
    "                                        COMMON_DATE_COLUMN, START_DATE_STR, END_DATE_STR)\n",
    "    \n",
    "    df_seorakdong_visitor = process_visitor_data(\n",
    "        VISITOR_RAW_FILE, visitor_col_map_korean_to_english, COMMON_DATE_COLUMN, \n",
    "        TARGET_DISTRICT_FOR_VISITORS, START_DATE_STR, END_DATE_STR\n",
    "    )\n",
    "\n",
    "    # --- Merge All Processed Data ---\n",
    "    print(\"\\n--- 4. Merging All Processed Data ---\")\n",
    "    try:\n",
    "        start_dt_merge = pd.to_datetime(START_DATE_STR)\n",
    "        end_dt_merge = pd.to_datetime(END_DATE_STR)\n",
    "        final_df = pd.DataFrame(pd.date_range(start=start_dt_merge, end=end_dt_merge, freq='D'), columns=[COMMON_DATE_COLUMN])\n",
    "    except Exception as e: print(f\"Error creating date range for final merge: {e}\"); exit()\n",
    "\n",
    "    dataframes_to_merge_final = [df_accident, df_weather, df_seorakdong_visitor]\n",
    "    \n",
    "    for i, df_merge_component in enumerate(dataframes_to_merge_final):\n",
    "        if df_merge_component is not None and not df_merge_component.empty and COMMON_DATE_COLUMN in df_merge_component.columns:\n",
    "            if not pd.api.types.is_datetime64_any_dtype(df_merge_component[COMMON_DATE_COLUMN]):\n",
    "                df_merge_component[COMMON_DATE_COLUMN] = pd.to_datetime(df_merge_component[COMMON_DATE_COLUMN], errors='coerce')\n",
    "            final_df = pd.merge(final_df, df_merge_component, on=COMMON_DATE_COLUMN, how='left')\n",
    "            print(f\"  Merged dataframe component {i+1}. Current shape: {final_df.shape}\")\n",
    "        else:\n",
    "            print(f\"  Skipping merge for dataframe component {i+1} (None, empty, or no date column).\")\n",
    "\n",
    "    # --- Final Touches ---\n",
    "    print(\"\\n--- 5. Applying Final Touches ---\")\n",
    "    for col in final_df.columns: # 결측치 처리\n",
    "        if col == COMMON_DATE_COLUMN: continue\n",
    "        if final_df[col].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(final_df[col]):\n",
    "                final_df[col].fillna(0, inplace=True)\n",
    "            elif final_df[col].apply(type).eq(list).all(): # 모든 유효값이 리스트인 경우\n",
    "                final_df[col] = final_df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "            else: # 그 외 (문자열 등)\n",
    "                final_df[col].fillna(\"\", inplace=True) # 빈 문자열로 채움\n",
    "\n",
    "    # 날짜 형식 문자열로 변경 (CSV 저장용)\n",
    "    final_df[COMMON_DATE_COLUMN] = final_df[COMMON_DATE_COLUMN].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # (선택 사항) 최종 컬럼 순서 정의\n",
    "    # desired_order = [COMMON_DATE_COLUMN, 'Total_Rescued_Count', 'Seorakdong_Visitor_Count', ...]\n",
    "    # final_df = final_df[[col for col in desired_order if col in final_df.columns] + \\\n",
    "    #                     [col for col in final_df.columns if col not in desired_order]]\n",
    "\n",
    "\n",
    "    # --- Save Final Merged Data ---\n",
    "    final_df.to_csv(FINAL_OUTPUT_MERGED_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n--- Final Merged Data Saved to {FINAL_OUTPUT_MERGED_FILE} ---\")\n",
    "    print(f\"Final DataFrame shape: {final_df.shape}\")\n",
    "    print(\"Final columns:\", final_df.columns.tolist())\n",
    "    print(\"Sample of final data:\")\n",
    "    print(final_df.head())\n",
    "\n",
    "    print(\"\\n========== All Data Processing and Merging Complete ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sunmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
